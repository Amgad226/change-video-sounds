import os
import cv2
import librosa
import numpy as np
import subprocess
import json
import threading
import hashlib
import math
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
from concurrent.futures import ProcessPoolExecutor, as_completed

CACHE_FILE = "analysis_cache.json"
cancel_processing = False  # Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¥Ù„ØºØ§Ø¡
AUDIO_ANALYSIS_SECONDS = 90  # Ù…Ø¯Ø© Ø¬Ø²Ø¦ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ ÙÙ‚Ø·

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ§Ø´ Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯
if os.path.exists(CACHE_FILE):
    with open(CACHE_FILE, "r", encoding="utf-8") as f:
        analysis_cache = json.load(f)
else:
    analysis_cache = {"videos": {}, "audios": {}}

def save_cache():
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(analysis_cache, f, ensure_ascii=False, indent=2)

# ===============================
# Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø©
# ===============================

def file_md5(path, chunk_size=2**20):
    md5 = hashlib.md5()
    with open(path, "rb") as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            md5.update(chunk)
    return md5.hexdigest()

def probe_duration(path):
    try:
        out = subprocess.check_output([
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            path
        ], stderr=subprocess.STDOUT).decode().strip()
        return round(float(out), 2)
    except Exception:
        return 0.0

def has_audio_stream(path):
    try:
        out = subprocess.check_output([
            "ffprobe", "-v", "error",
            "-select_streams", "a", "-show_entries", "stream=index",
            "-of", "csv=p=0", path
        ], stderr=subprocess.STDOUT).decode().strip()
        return bool(out)
    except Exception:
        return False

# ===============================
# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª (Ù†Ø³Ø® Ø³Ø±ÙŠØ¹)
# ===============================

def remove_audio_from_videos(input_dir, temp_dir, progress_callback=None):
    os.makedirs(temp_dir, exist_ok=True)
    video_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.mp4', '.mov', '.avi', '.mkv'))]

    for i, filename in enumerate(video_files):
        if cancel_processing:
            break
        try:
            input_path = os.path.join(input_dir, filename)
            output_path = os.path.join(temp_dir, filename)
            command = [
                "ffmpeg", "-y",
                "-i", input_path,
                "-map", "0:v:0",
                "-c:v", "copy",
                "-an",
                "-movflags", "+faststart",
                output_path
            ]
            subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)
            if progress_callback:
                progress_callback(i + 1, len(video_files))
        except Exception as e:
            messagebox.showerror("Ø®Ø·Ø£ ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙˆØª", f"âŒ {filename}:\n{str(e)}")

# ===============================
# ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
# ===============================

def analyze_video(video_path):
    if video_path in analysis_cache["videos"]:
        return video_path, analysis_cache["videos"][video_path]["duration"], analysis_cache["videos"][video_path]["motion"]

    try:
        cap = cv2.VideoCapture(video_path)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        duration = frame_count / fps if fps else probe_duration(video_path)
        motion_score = []
        prev_frame = None

        step = int(fps) if fps and fps > 0 else 1  # Ù„Ù‚Ø·Ø© ÙƒÙ„ Ø«Ø§Ù†ÙŠØ©

        for i in range(0, int(frame_count), step):
            cap.set(cv2.CAP_PROP_POS_FRAMES, i)
            ret, frame = cap.read()
            if not ret:
                break
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.resize(gray, (160, 90))
            if prev_frame is not None:
                diff = cv2.absdiff(prev_frame, gray)
                motion_score.append(np.mean(diff))
            prev_frame = gray

        cap.release()
        avg_motion = np.mean(motion_score) if motion_score else 0
        analysis_cache["videos"][video_path] = {"duration": round(duration, 2), "motion": round(avg_motion, 2)}
        save_cache()
        return video_path, round(duration, 2), round(avg_motion, 2)
    except Exception:
        return video_path, 0, 0

# ===============================
# ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª (Ù‚Ø¨ÙˆÙ„ Ø¨Ø¯ÙˆÙ† Tempo Ø¥Ø°Ø§ ØªØ¹Ø°Ù‘Ø±)
# ===============================

def analyze_audio(audio_path):
    # ÙƒØ§Ø´
    if audio_path in analysis_cache["audios"]:
        d = analysis_cache["audios"][audio_path]["duration"]
        t = analysis_cache["audios"][audio_path].get("tempo")
        return audio_path, d, t

    duration = probe_duration(audio_path)  # Ù†Ø­Ø§ÙˆÙ„ ffprobe Ø£ÙˆÙ„Ø§Ù‹
    tempo = None

    try:
        # ØªØ­Ù…ÙŠÙ„ Ø¬Ø²Ø¦ÙŠ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ ÙÙ‚Ø· (ØªØ®ÙÙŠÙÙ‹Ø§ Ù„Ù„ÙˆÙ‚Øª/Ø§Ù„Ø°Ø§ÙƒØ±Ø©)
        y, sr = librosa.load(audio_path, mono=True, sr=22050,
                             duration=AUDIO_ANALYSIS_SECONDS, res_type="kaiser_fast")
        if not duration or duration <= 0:
            duration = librosa.get_duration(y=y, sr=sr)

        t, _ = librosa.beat.beat_track(y=y, sr=sr)
        t = float(t)
        # Ù„Ùˆ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ ØµÙØ± (Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø£Ù…Ø¨ÙŠØ§Ù†Øª)ØŒ Ù†Ø¹Ø¯Ù‘Ù‡ ØºÙŠØ± Ù…ØªØ§Ø­
        if t > 0:
            tempo = t
    except Exception:
        # Ù„Ø§ Ù…Ø´ÙƒÙ„Ø©: Ø³Ù†Ù‚Ø¨Ù„ Ø§Ù„Ù…Ù„Ù Ø·Ø§Ù„Ù…Ø§ Ø§Ù„Ù…Ø¯Ø© Ù…Ø¹Ø±ÙˆÙØ©
        pass

    # Ù„Ø§ Ù†Ù‚Ø¨Ù„ Ø¥Ù„Ø§ Ù„Ùˆ Ø§Ù„Ù…Ø¯Ø© Ù…Ø¹Ø±ÙˆÙØ© ÙˆÙ…ÙˆØ¬Ø¨Ø©
    if not duration or duration <= 0:
        return audio_path, None, None

    # Ø®Ø²Ù† ÙÙŠ Ø§Ù„ÙƒØ§Ø´
    analysis_cache["audios"][audio_path] = {
        "duration": round(duration, 2),
        "tempo": round(tempo, 2) if tempo is not None else None
    }
    save_cache()

    return audio_path, round(duration, 2), (round(tempo, 2) if tempo is not None else None)

# ===============================
# ØªØµÙ†ÙŠÙ (ØºÙŠØ± Ø¥Ù„Ø²Ø§Ù…ÙŠ Ù„Ù„Ø±Ø¨Ø· Ø§Ù„Ø­Ø§Ù„ÙŠ)
# ===============================

def get_motion_category(motion):
    if motion >= 15:
        return "fast"
    elif motion >= 3:
        return "medium"
    return "slow"

def get_tempo_category(tempo):
    if tempo is None:
        return "slow"
    if tempo >= 120:
        return "fast"
    elif tempo >= 90:
        return "medium"
    return "slow"

# ===============================
# Ø§Ù„Ø¯Ù…Ø¬ Ù…Ø¹ Fade-in/Fade-out
# ===============================

def merge_audio_video_with_fade(video_path, audio_path, output_path, video_duration):
    base, _ = os.path.splitext(output_path)
    out_mp4 = base + ".mp4"

    # Ø­Ø³Ø§Ø¨ Ø£Ø²Ù…Ù†Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„/Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„ØµÙˆØªÙŠ
    if video_duration and video_duration > 4:
        fade_in_d = 2.0
        fade_out_d = 2.0
        fade_out_start = max(0.0, float(video_duration) - fade_out_d)
    else:
        fade_in_d = max(0.2, (video_duration or 4) / 8.0)
        fade_out_d = fade_in_d
        fade_out_start = max(0.0, float(video_duration or 4) - fade_out_d)

    afilter = f"afade=t=in:st=0:d={fade_in_d},afade=t=out:st={fade_out_start}:d={fade_out_d}"

    # Ù…Ø­Ø§ÙˆÙ„Ø© 1: Ù†Ø³Ø® Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    cmd_copy = [
        "ffmpeg", "-y",
        "-i", video_path, "-i", audio_path,
        "-map", "0:v:0", "-map", "1:a:0",
        "-c:v", "copy",
        "-filter:a", afilter,
        "-c:a", "aac", "-b:a", "128k",
        "-shortest",
        "-movflags", "+faststart",
        out_mp4
    ]
    try:
        subprocess.run(cmd_copy, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)
        if not has_audio_stream(out_mp4):
            raise RuntimeError("no audio after copy")
        return out_mp4
    except Exception:
        # Ù…Ø­Ø§ÙˆÙ„Ø© 2: Ø¥Ø¹Ø§Ø¯Ø© ØªØ±Ù…ÙŠØ² Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙÙ‚Ø· Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
        cmd_reencode = [
            "ffmpeg", "-y",
            "-i", video_path, "-i", audio_path,
            "-map", "0:v:0", "-map", "1:a:0",
            "-c:v", "libx264", "-preset", "fast", "-crf", "23",
            "-filter:a", afilter,
            "-c:a", "aac", "-b:a", "128k",
            "-shortest",
            "-movflags", "+faststart",
            out_mp4
        ]
        subprocess.run(cmd_reencode, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)
        if not has_audio_stream(out_mp4):
            raise RuntimeError("no audio in output")
        return out_mp4

# ===============================
# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØµÙˆØª Ù„ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ (Ø¨Ø¯ÙˆÙ† ÙÙŠØ¯ÙŠÙˆ ØµØ§Ù…Øª)
# ===============================

def assign_audios_to_videos(video_analysis, available_audios):
    """
    ÙŠØ¶Ù…Ù† Ø£Ù† ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ ÙŠÙ…Ù„Ùƒ ØµÙˆØªÙ‹Ø§:
      - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£ØµÙˆØ§Øª >= Ø¹Ø¯Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª: ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ ØµÙˆØª Ù…Ø®ØªÙ„Ù (ÙØ±ÙŠØ¯) Ø­ØªÙ‰ Ù„Ùˆ ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚.
      - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª > Ø¹Ø¯Ø¯ Ø§Ù„Ø£ØµÙˆØ§Øª: ÙŠØ³Ù…Ø­ Ø¨Ø§Ù„ØªÙƒØ±Ø§Ø± Ù…Ø¹ ØªÙˆØ²ÙŠØ¹ Ù…ØªÙˆØ§Ø²Ù†.
    ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ù‚Ø±Ø¨ ÙÙŠ Ø§Ù„Ù…Ø¯Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª.
    """
    if not available_audios:
        for v in video_analysis:
            v["audio"] = None
        return

    for a in available_audios:
        a.setdefault("use_count", 0)
        a.setdefault("duration", float(a.get("duration") or 0.0))
    for v in video_analysis:
        v.setdefault("duration", float(v.get("duration") or 0.0))

    V = len(video_analysis)
    A = len(available_audios)

    if A >= V:
        remaining_audios = available_audios.copy()
        videos_sorted = sorted(video_analysis, key=lambda x: x["duration"], reverse=True)
        for v in videos_sorted:
            best_idx = min(range(len(remaining_audios)), key=lambda i: abs(remaining_audios[i]["duration"] - v["duration"]))
            chosen = remaining_audios.pop(best_idx)
            v["audio"] = chosen
            chosen["use_count"] += 1
        return

    # A < V -> Ù†ÙˆØ²Ù‘Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¨Ø§Ù„ØªØ³Ø§ÙˆÙŠ
    base = V // A
    extra = V % A
    quotas = [base + (1 if i < extra else 0) for i in range(A)]

    audios_sorted = sorted(available_audios, key=lambda x: x["duration"], reverse=True)
    remaining_videos = sorted(video_analysis, key=lambda x: x["duration"], reverse=True)

    for idx, a in enumerate(audios_sorted):
        q = quotas[idx]
        for _ in range(q):
            if not remaining_videos:
                break
            best_vid_idx = min(range(len(remaining_videos)), key=lambda i: abs(remaining_videos[i]["duration"] - a["duration"]))
            v = remaining_videos.pop(best_vid_idx)
            v["audio"] = a
            a["use_count"] += 1

    while remaining_videos:
        v = remaining_videos.pop(0)
        a = min(available_audios, key=lambda x: (x["use_count"], abs(x["duration"] - v["duration"])))
        v["audio"] = a
        a["use_count"] += 1

# ===============================
# Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
# ===============================

def process_all(videos_dir, audios_dir, output_dir, update_progress):
    global cancel_processing
    cancel_processing = False

    try:
        messagebox.showinfo("Ø§Ù„Ø¨Ø¯Ø¡", "ğŸ”„ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª...")
        os.makedirs(output_dir, exist_ok=True)
        temp_dir = os.path.join(videos_dir, "_no_audio_temp")
        remove_audio_from_videos(videos_dir, temp_dir)

        if cancel_processing:
            messagebox.showinfo("Ø¥Ù„ØºØ§Ø¡", "âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")
            return

        video_files = [os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.lower().endswith(('.mp4', '.mov', '.avi', '.mkv'))]
        audio_files = [os.path.join(audios_dir, f) for f in os.listdir(audios_dir) if f.lower().endswith(('.mp3', '.wav', '.m4a', '.flac'))]

        if not audio_files:
            messagebox.showerror("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£ØµÙˆØ§Øª", "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª ØµÙˆØª. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø¨Ù„Ø§ ØµÙˆØª.")
            return

        # ---- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ØµÙˆØ§Øª Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ ----
        available_audios = []
        with ProcessPoolExecutor() as executor:
            futures = [executor.submit(analyze_audio, audio) for audio in audio_files]
            for i, future in enumerate(as_completed(futures)):
                if cancel_processing:
                    break
                audio_path, duration, tempo = future.result()
                # âœ… Ù†Ù‚Ø¨Ù„ Ø§Ù„ØµÙˆØª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¯Ø© > 0 Ø­ØªÙ‰ Ù„Ùˆ tempo ØºÙŠØ± Ù…ØªØ§Ø­
                if duration and duration > 0:
                    available_audios.append({
                        "file": os.path.basename(audio_path),
                        "path": audio_path,
                        "duration": duration,
                        "tempo": tempo  # Ù‚Ø¯ ÙŠÙƒÙˆÙ† NoneØŒ Ù„Ø§ Ù…Ø´ÙƒÙ„Ø©
                    })

        if cancel_processing:
            messagebox.showinfo("Ø¥Ù„ØºØ§Ø¡", "âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")
            return

        if not available_audios:
            messagebox.showerror("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£ØµÙˆØ§Øª ØµØ§Ù„Ø­Ø©", "âŒ ØªØ¹Ø°Ù‘Ø± ØªØ­Ù„ÙŠÙ„ Ø£ÙŠ Ù…Ù„Ù ØµÙˆØª (Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ù…Ù„ÙØ§Øª ØªØ§Ù„ÙØ©/ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©).")
            return

        # ---- ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ ----
        video_analysis = []
        with ProcessPoolExecutor() as executor:
            futures = [executor.submit(analyze_video, video) for video in video_files]
            for i, future in enumerate(as_completed(futures)):
                if cancel_processing:
                    break
                video_path, duration, motion = future.result()
                motion_cat = get_motion_category(motion)
                video_analysis.append({
                    "file": os.path.basename(video_path),
                    "path": video_path,
                    "duration": duration,
                    "motion_cat": motion_cat,
                    "audio": None
                })
                update_progress(i + 1, len(video_files))

        if cancel_processing:
            messagebox.showinfo("Ø¥Ù„ØºØ§Ø¡", "âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")
            return

        # ---- ØªØ¹ÙŠÙŠÙ† ØµÙˆØª Ù„ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ (Ø¯Ø§Ø¦Ù…Ù‹Ø§) ----
        assign_audios_to_videos(video_analysis, available_audios)

        # ØªØ£ÙƒÙŠØ¯ Ù†Ù‡Ø§Ø¦ÙŠ: Ø¹ÙŠÙ‘Ù† Ø§Ù„Ø£Ù‚Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‹Ø§ Ù„Ø£ÙŠ ÙÙŠØ¯ÙŠÙˆ Ø¨Ù„Ø§ ØµÙˆØª (ØªØ­Ø³Ø¨Ù‹Ø§)
        for v in video_analysis:
            if not v.get("audio"):
                a = min(available_audios, key=lambda x: x["use_count"])
                v["audio"] = a
                a["use_count"] += 1

        # ---- Ø§Ù„Ø¯Ù…Ø¬ Ù…Ø¹ Fade Ù„ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ ----
        for i, video in enumerate(video_analysis):
            if cancel_processing:
                break
            output_path = os.path.join(output_dir, video["file"])
            try:
                merge_audio_video_with_fade(video["path"], video["audio"]["path"], output_path, video["duration"])
            except Exception as e:
                # Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨ØªØ±Ù…ÙŠØ² (Ù†ÙØ³ Ø§Ù„Ø¯Ø§Ù„Ø© ØªÙ‚ÙˆÙ… Ø¨Ù‡Ø°Ø§ ØºØ§Ù„Ø¨Ù‹Ø§)ØŒ ÙˆØ¥Ù† ÙØ´Ù„ Ù†ØªØ®Ø·Ù‰ Ø¯ÙˆÙ† Ø¥Ù†ØªØ§Ø¬ ØµØ§Ù…Øª
                try:
                    merge_audio_video_with_fade(video["path"], video["audio"]["path"], output_path, video["duration"])
                except Exception as e2:
                    messagebox.showerror("Ø®Ø·Ø£ Ø¯Ù…Ø¬", f"ÙØ´Ù„ Ø¯Ù…Ø¬ {video['file']} Ù…Ø¹ {video['audio']['file']}:\n{e2}")

            update_progress(i + 1, len(video_analysis))

        if cancel_processing:
            messagebox.showinfo("Ø¥Ù„ØºØ§Ø¡", "âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")
        else:
            messagebox.showinfo("ØªÙ…", "âœ… ØªÙ… Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        messagebox.showerror("Ø®Ø·Ø£", str(e))

# ===============================
# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
# ===============================

def run_gui():
    root = tk.Tk()
    root.title("ğŸ”Š Ø¯Ù…Ø¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ (ØµÙˆØª Ù…Ø®ØªÙ„Ù Ù„ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ + Fade)")

    video_dir_var = tk.StringVar()
    audio_dir_var = tk.StringVar()
    output_dir_var = tk.StringVar()

    def browse_dir(var):
        var.set(filedialog.askdirectory())

    def update_progress(current, total):
        progress_var.set((current / max(1, total)) * 100)
        progress_label.config(text=f"{current} Ù…Ù† {total} ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡")
        root.update_idletasks()

    def start():
        global cancel_processing
        cancel_processing = False
        if not video_dir_var.get() or not audio_dir_var.get():
            messagebox.showwarning("ØªØ­Ø°ÙŠØ±", "ÙŠØ±Ø¬Ù‰ ØªØ­Ø¯ÙŠØ¯ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ÙˆØ§Ù„Ø£ØµÙˆØ§Øª.")
            return
        threading.Thread(target=process_all, args=(video_dir_var.get(), audio_dir_var.get(), output_dir_var.get() or "output", update_progress), daemon=True).start()

    def cancel():
        global cancel_processing
        cancel_processing = True
        messagebox.showinfo("Ø¥Ù„ØºØ§Ø¡", "âŒ Ø¬Ø§Ø±ÙŠ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ©...")

    tk.Label(root, text="ğŸ“ Ù…Ø¬Ù„Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª:").grid(row=0, column=0, sticky="e")
    tk.Entry(root, textvariable=video_dir_var, width=50).grid(row=0, column=1)
    tk.Button(root, text="Ø§Ø®ØªÙŠØ§Ø±", command=lambda: browse_dir(video_dir_var)).grid(row=0, column=2)

    tk.Label(root, text="ğŸµ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£ØµÙˆØ§Øª:").grid(row=1, column=0, sticky="e")
    tk.Entry(root, textvariable=audio_dir_var, width=50).grid(row=1, column=1)
    tk.Button(root, text="Ø§Ø®ØªÙŠØ§Ø±", command=lambda: browse_dir(audio_dir_var)).grid(row=1, column=2)

    tk.Label(root, text="ğŸ’¾ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­ÙØ¸:").grid(row=2, column=0, sticky="e")
    tk.Entry(root, textvariable=output_dir_var, width=50).grid(row=2, column=1)
    tk.Button(root, text="Ø§Ø®ØªÙŠØ§Ø±", command=lambda: browse_dir(output_dir_var)).grid(row=2, column=2)

    tk.Button(root, text="Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", bg="green", fg="white", width=20, command=start).grid(row=3, column=1, pady=10)
    tk.Button(root, text="Ø¥Ù„ØºØ§Ø¡", bg="red", fg="white", width=20, command=cancel).grid(row=4, column=1, pady=10)

    progress_var = tk.DoubleVar()
    progress_label = tk.Label(root, text="")
    progress_label.grid(row=5, column=1)
    progress_bar = ttk.Progressbar(root, variable=progress_var, maximum=100)
    progress_bar.grid(row=6, column=0, columnspan=3, padx=20, pady=10, sticky="we")

    root.mainloop()

if __name__ == "__main__":
    run_gui()
